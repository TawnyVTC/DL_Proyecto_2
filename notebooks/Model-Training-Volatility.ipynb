{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d7ae2a77",
      "metadata": {
        "id": "d7ae2a77"
      },
      "source": [
        "# **Modelado: Volatilidad**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "11cf53c0",
      "metadata": {
        "id": "11cf53c0",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e3a535a4",
      "metadata": {
        "id": "e3a535a4",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "btc = pd.read_csv(r'https://raw.githubusercontent.com/TawnyVTC/Proyectos_UN/refs/heads/main/2025/Deep_Learning/Data/btc_1d_with_volatility_and_lags.csv')\n",
        "btc['Open time'] = pd.to_datetime(btc['Open time'], format='%Y-%m-%d')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e75XJV58q1XK",
      "metadata": {
        "id": "e75XJV58q1XK"
      },
      "source": [
        "## **Split Temporal y Validaci√≥n Cruzada**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d77354",
      "metadata": {},
      "source": [
        "En esta secci√≥n se replica la misma l√≥gica empleada para la predicci√≥n del precio de cierre, pero enfocada en la volatilidad del Bitcoin. Primero, se generan variables retardadas de la volatilidad (lags de 7, 14, 21 y 28 d√≠as), que capturan la dependencia temporal del indicador y permiten al modelo aprender patrones hist√≥ricos. Posteriormente, se crean los objetivos futuros correspondientes a los pr√≥ximos siete d√≠as (t+1 a t+7), de modo que el modelo pueda realizar predicciones multihorizonte.\n",
        "\n",
        "Las caracter√≠sticas de entrada incluyen tanto variables del precio (Close, LogReturn) como las medidas de volatilidad actual y retardada, buscando combinar informaci√≥n de nivel y dispersi√≥n. Finalmente, se eliminan los valores faltantes generados por los desplazamientos y se construyen las matrices de entrada (X) y salida (y) que alimentar√°n el flujo principal de entrenamiento, conformando el objeto timeSeries con el que se aplicar√°n los mismos experimentos de evaluaci√≥n por n√∫mero de lags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0430259",
      "metadata": {
        "id": "d0430259"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# 1. Crear lags de volatilidad\n",
        "# -----------------------\n",
        "for lag in [7, 14, 21, 28]:\n",
        "    btc[f'Volatility_lag_{lag}'] = btc['Volatility'].shift(lag)\n",
        "\n",
        "# -----------------------\n",
        "# 2. Crear targets futuros (predicciones de volatilidad)\n",
        "# -----------------------\n",
        "for i in range(1, 8):  # t+1 a t+7\n",
        "    btc[f'target_vol_t+{i}'] = btc['Volatility'].shift(-i)\n",
        "\n",
        "# -----------------------\n",
        "# 3. Definir features y targets\n",
        "# -----------------------\n",
        "features = [\n",
        "    'Close', 'LogReturn', 'Volatility',\n",
        "    'Volatility_lag_7', 'Volatility_lag_14', 'Volatility_lag_21', 'Volatility_lag_28'\n",
        "]\n",
        "\n",
        "targets = [f'target_vol_t+{i}' for i in range(1, 8)]\n",
        "\n",
        "# -----------------------\n",
        "# 4. Eliminar filas con NaN (por los shifts)\n",
        "# -----------------------\n",
        "btc = btc.dropna(subset=features + targets).reset_index(drop=True)\n",
        "\n",
        "# -----------------------\n",
        "# 5. Definir matrices de entrada y salida\n",
        "# -----------------------\n",
        "X = btc[features].values\n",
        "y = btc[targets].values\n",
        "dates = btc[\"Open time\"].values\n",
        "\n",
        "# -----------------------\n",
        "# 6. Construcci√≥n del objeto timeSeries\n",
        "# -----------------------\n",
        "timeSeries = np.concatenate([X, y], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1243fb76",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Gr2anZEbq-Yh",
      "metadata": {
        "id": "Gr2anZEbq-Yh",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from tsxv.splitTrainValTest import split_train_val_test_groupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def _ensure_2d(arr):\n",
        "    \"\"\"\n",
        "    Convierte el array a formato 2D.\n",
        "    Si llega 1D ‚Üí (n,1); si llega 3D ‚Üí (n, timesteps*feats)\n",
        "    \"\"\"\n",
        "    arr = np.asarray(arr)\n",
        "    if arr.ndim == 1:\n",
        "        return arr.reshape(-1, 1)\n",
        "    if arr.ndim == 2:\n",
        "        return arr\n",
        "    if arr.ndim == 3:\n",
        "        n, a, b = arr.shape\n",
        "        return arr.reshape(n, a * b)\n",
        "    raise ValueError(f\"Array con ndim={arr.ndim} no soportado por esta funci√≥n.\")\n",
        "\n",
        "\n",
        "def split_and_scale(timeSeries, n_steps_input=7, n_steps_forecast=7, n_steps_jump=1, target_col=2):\n",
        "    X_list, y_list, Xcv_list, ycv_list, Xtest_list, ytest_list = split_train_val_test_groupKFold(\n",
        "        timeSeries,\n",
        "        n_steps_input,\n",
        "        n_steps_forecast,\n",
        "        n_steps_jump\n",
        "    )\n",
        "\n",
        "    X_train_scaled, X_val_scaled, X_test_scaled = [], [], []\n",
        "    y_train_scaled, y_val_scaled, y_test_scaled = [], [], []\n",
        "    scalers_x, scalers_y = [], []\n",
        "\n",
        "    for fold in range(len(X_list)):\n",
        "        X_train_raw = _ensure_2d(X_list[fold])\n",
        "        X_val_raw   = _ensure_2d(Xcv_list[fold])\n",
        "        X_test_raw  = _ensure_2d(Xtest_list[fold])\n",
        "\n",
        "        # üëá Aqu√≠ filtramos solo la variable objetivo (columna target)\n",
        "        y_train_raw = _ensure_2d(y_list[fold])[:, target_col:target_col + n_steps_forecast]\n",
        "        y_val_raw   = _ensure_2d(ycv_list[fold])[:, target_col:target_col + n_steps_forecast]\n",
        "        y_test_raw  = _ensure_2d(ytest_list[fold])[:, target_col:target_col + n_steps_forecast]\n",
        "\n",
        "        # Escaladores\n",
        "        scaler_x = StandardScaler().fit(X_train_raw)\n",
        "        scaler_y = StandardScaler().fit(y_train_raw)\n",
        "\n",
        "        X_train_scaled.append(scaler_x.transform(X_train_raw))\n",
        "        X_val_scaled.append(scaler_x.transform(X_val_raw))\n",
        "        X_test_scaled.append(scaler_x.transform(X_test_raw))\n",
        "        y_train_scaled.append(scaler_y.transform(y_train_raw))\n",
        "        y_val_scaled.append(scaler_y.transform(y_val_raw))\n",
        "        y_test_scaled.append(scaler_y.transform(y_test_raw))\n",
        "\n",
        "        scalers_x.append(scaler_x)\n",
        "        scalers_y.append(scaler_y)\n",
        "\n",
        "        print(f\"Fold {fold+1}: train {X_train_raw.shape} -> val {X_val_raw.shape} -> test {X_test_raw.shape}\")\n",
        "\n",
        "    return {\n",
        "        'X_train': X_train_scaled,\n",
        "        'X_val': X_val_scaled,\n",
        "        'X_test': X_test_scaled,\n",
        "        'y_train': y_train_scaled,\n",
        "        'y_val': y_val_scaled,\n",
        "        'y_test': y_test_scaled,\n",
        "        'scalers_x': scalers_x,\n",
        "        'scalers_y': scalers_y\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U1b8-yzuq71m",
      "metadata": {
        "id": "U1b8-yzuq71m"
      },
      "source": [
        "## **Modelado con Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e37fe85",
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "oLzRsaLeMG60",
      "metadata": {
        "id": "oLzRsaLeMG60",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "def test_independencia_residuos(residuos, lags=10):\n",
        "    resultado = acorr_ljungbox(residuos, lags=[lags], return_df=True)\n",
        "    return resultado['lb_pvalue'].iloc[0]\n",
        "\n",
        "def _calc_metrics_per_horizon(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true, y_pred: arrays (n_samples, n_horizons)\n",
        "    Devuelve DataFrame con m√©tricas por horizonte.\n",
        "    \"\"\"\n",
        "    n_outputs = y_true.shape[1]\n",
        "    rows = []\n",
        "    for h in range(n_outputs):\n",
        "        yt = y_true[:, h]\n",
        "        yp = y_pred[:, h]\n",
        "        mae = mean_absolute_error(yt, yp)\n",
        "        mse = mean_squared_error(yt, yp)\n",
        "        rmse = np.sqrt(mse)\n",
        "        # MAPE con epsilon para evitar divisi√≥n por cero\n",
        "        mape = np.mean(np.abs((yt - yp) / (np.abs(yt) + 1e-8))) * 100\n",
        "        rows.append({'Horizonte': h+1, 'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape})\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Q6FDl1KrMQbJ",
      "metadata": {
        "id": "Q6FDl1KrMQbJ",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "def entrenar_mlp_folds(data_dict, n_outputs=7, epochs=100, batch_size=32, verbose_fit=0):\n",
        "    \"\"\"\n",
        "    Versi√≥n extendida:\n",
        "    - Devuelve: resultados (lista), tablas_folds (lista de df_metrics por fold)\n",
        "    - Cada df_metrics tiene m√©tricas por horizonte + fila 'Promedio'\n",
        "    \"\"\"\n",
        "    resultados = []\n",
        "    tablas_folds = []\n",
        "\n",
        "    for fold in range(len(data_dict['X_train'])):\n",
        "        print(f\"\\n===== Fold {fold+1}/{len(data_dict['X_train'])} =====\")\n",
        "\n",
        "        X_train, X_val, X_test = data_dict['X_train'][fold], data_dict['X_val'][fold], data_dict['X_test'][fold]\n",
        "        y_train, y_val, y_test = data_dict['y_train'][fold], data_dict['y_val'][fold], data_dict['y_test'][fold]\n",
        "        scaler_y = data_dict['scalers_y'][fold]\n",
        "\n",
        "        # --- Modelo ---\n",
        "        model = Sequential([\n",
        "            Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "            Dropout(0.2),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(n_outputs)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                  epochs=epochs, batch_size=batch_size, verbose=verbose_fit, callbacks=[es])\n",
        "\n",
        "        # --- Predicciones (desescaladas) ---\n",
        "        yhat_train = scaler_y.inverse_transform(model.predict(X_train))\n",
        "        yhat_val = scaler_y.inverse_transform(model.predict(X_val))\n",
        "        yhat_test = scaler_y.inverse_transform(model.predict(X_test))\n",
        "        ytrain_real = scaler_y.inverse_transform(y_train)\n",
        "        yval_real = scaler_y.inverse_transform(y_val)\n",
        "        ytest_real = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "        # --- M√©tricas por horizonte (test) ---\n",
        "        df_metrics = _calc_metrics_per_horizon(ytest_real, yhat_test)\n",
        "        # a√±adir fila promedio\n",
        "        promedio = df_metrics.mean(numeric_only=True).to_dict()\n",
        "        promedio['Horizonte'] = 'Promedio'\n",
        "        df_metrics = pd.concat([df_metrics, pd.DataFrame([promedio])], ignore_index=True)\n",
        "\n",
        "        # p-value BDS en residuos del horizonte 1 (h=1)\n",
        "        resid_h1 = ytest_real[:, 0] - yhat_test[:, 0]\n",
        "        try:\n",
        "            pval = test_independencia_residuos(resid_h1, lags=10)\n",
        "        except Exception as e:\n",
        "            pval = np.nan\n",
        "\n",
        "        # agregamos columna BDS_pvalue_h1 (solo en la primera fila ser√° pval)\n",
        "        bds_col = [np.nan] * len(df_metrics)\n",
        "        if len(df_metrics) > 0:\n",
        "            bds_col[0] = pval\n",
        "        df_metrics['BDS_pvalue_h1'] = bds_col\n",
        "\n",
        "        # print resumen por fold\n",
        "        print(f\"Fold {fold+1} | RMSE prom: {df_metrics.loc[df_metrics['Horizonte']=='Promedio','RMSE'].values[0]:.4f} | pval(h1): {pval}\")\n",
        "\n",
        "        resultados.append({\n",
        "            'fold': fold+1,\n",
        "            'rmse_test_prom': df_metrics.loc[df_metrics['Horizonte']=='Promedio','RMSE'].values[0],\n",
        "            'pval_h1': pval,\n",
        "            'y_train_real': ytrain_real, 'y_train_pred': yhat_train,\n",
        "            'y_val_real': yval_real, 'y_val_pred': yhat_val,\n",
        "            'y_test_real': ytest_real, 'y_test_pred': yhat_test,\n",
        "            'df_metrics': df_metrics\n",
        "        })\n",
        "\n",
        "        tablas_folds.append(df_metrics)\n",
        "\n",
        "    return resultados, tablas_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "TcXxpG_zMQYb",
      "metadata": {
        "id": "TcXxpG_zMQYb",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Funciones para agregar resultados por lag y crear tablas resumen\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "def resumen_por_lag(tablas_folds):\n",
        "    \"\"\"\n",
        "    tablas_folds: lista de dataframes (uno por fold), cada df tiene las filas por horizonte + 'Promedio'.\n",
        "    Devuelve df resumen por horizonte con mean y std entre folds.\n",
        "    \"\"\"\n",
        "    # extraer solo filas de horizonte 1..H (no 'Promedio') para hacer stats por horizonte\n",
        "    # asumimos que todos los df tienen la misma cantidad de horizontes antes de la fila Promedio\n",
        "    list_horizon_dfs = []\n",
        "    for df in tablas_folds:\n",
        "        # seleccionar solo filas cuyo 'Horizonte' no sea 'Promedio'\n",
        "        df_h = df[df['Horizonte'] != 'Promedio'].copy()\n",
        "        df_h = df_h.reset_index(drop=True)\n",
        "        list_horizon_dfs.append(df_h)\n",
        "\n",
        "    # concatenar en multiindex: fold, horizonte\n",
        "    concat = pd.concat(list_horizon_dfs, keys=range(1, len(list_horizon_dfs)+1), names=['fold','row'])\n",
        "    # Queremos agrupar por horizonte y calcular mean/std de m√©tricas\n",
        "    metrics = ['MAPE','MAE','RMSE','MSE']\n",
        "    summary_rows = []\n",
        "    for h in sorted(concat['Horizonte'].unique(), key=lambda x: int(x)):\n",
        "        sel = concat[concat['Horizonte']==h]\n",
        "        row = {'Horizonte': int(h)}\n",
        "        for m in metrics:\n",
        "            row[f'{m}_mean'] = sel[m].mean()\n",
        "            row[f'{m}_std'] = sel[m].std()\n",
        "        # p-value mean across folds: buscar pval en fold df (est√° en la primera fila BDS_pvalue_h1)\n",
        "        # coletar pvals\n",
        "        pvals = []\n",
        "        for df in tablas_folds:\n",
        "            pv = df['BDS_pvalue_h1'].iloc[0]\n",
        "            if not np.isnan(pv):\n",
        "                pvals.append(pv)\n",
        "        row['BDS_pvalue_h1_mean'] = np.mean(pvals) if len(pvals)>0 else np.nan\n",
        "        row['BDS_pvalue_h1_std'] = np.std(pvals) if len(pvals)>0 else np.nan\n",
        "\n",
        "        summary_rows.append(row)\n",
        "\n",
        "    df_summary = pd.DataFrame(summary_rows)\n",
        "    return df_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "tYkQZDkBMQVp",
      "metadata": {
        "id": "tYkQZDkBMQVp",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Funci√≥n principal: eval√∫a lista de lags y devuelve todo lo necesario\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "def evaluar_y_reportar(timeSeries, lags_list=[7,14,21,28], n_outputs=7,\n",
        "                        epochs=80, batch_size=32, verbose_fit=0):\n",
        "    \"\"\"\n",
        "    Ejecuta todo el flujo para cada n_lag:\n",
        "    - split + scale\n",
        "    - entrenar por folds\n",
        "    - guarda tablas por fold y resumen por lag (mean + std)\n",
        "    - devuelve estructura con todo para plotting y tablas\n",
        "    \"\"\"\n",
        "    todos_lags = {}\n",
        "    comparativa_resumen = []\n",
        "\n",
        "    for n_lag in lags_list:\n",
        "        print(f\"\\n=== Procesando n_lag = {n_lag} ===\")\n",
        "        data_dict = split_and_scale(timeSeries, n_steps_input=n_lag, n_steps_forecast=n_outputs)\n",
        "        resultados, tablas_folds = entrenar_mlp_folds(data_dict, n_outputs=n_outputs,\n",
        "                                                     epochs=epochs, batch_size=batch_size,\n",
        "                                                     verbose_fit=verbose_fit)\n",
        "\n",
        "        # df concatenado de m√©tricas (todos los folds)\n",
        "        df_metricas_comb = pd.concat([t.reset_index(drop=True) for t in tablas_folds], keys=range(1, len(tablas_folds)+1),\n",
        "                                      names=['fold','row']).reset_index()\n",
        "        # resumen por horizonte (mean, std)\n",
        "        df_summary_h = resumen_por_lag(tablas_folds)\n",
        "\n",
        "        # resumen global (media de RMSE, MAE, MAPE, MSE y pval promedio)\n",
        "        rmse_prom = df_metricas_comb.groupby('Horizonte')['RMSE'].mean().mean()  # promedio de horizontes\n",
        "        mae_prom  = df_metricas_comb.groupby('Horizonte')['MAE'].mean().mean()\n",
        "        mape_prom = df_metricas_comb.groupby('Horizonte')['MAPE'].mean().mean()\n",
        "        mse_prom  = df_metricas_comb.groupby('Horizonte')['MSE'].mean().mean()\n",
        "        pvals = df_metricas_comb['BDS_pvalue_h1'].dropna()\n",
        "        pval_prom = pvals.mean() if len(pvals)>0 else np.nan\n",
        "\n",
        "        comparativa_resumen.append({\n",
        "            'n_lag': n_lag,\n",
        "            'RMSE_prom': rmse_prom,\n",
        "            'RMSE_std': df_metricas_comb.groupby('Horizonte')['RMSE'].mean().std(),\n",
        "            'MAE_prom': mae_prom,\n",
        "            'MAPE_prom': mape_prom,\n",
        "            'MSE_prom': mse_prom,\n",
        "            'BDS_pvalue_h1_prom': pval_prom\n",
        "        })\n",
        "\n",
        "        todos_lags[n_lag] = {\n",
        "            'resultados': resultados,         # lista de dict por fold (incluye df_metrics por fold)\n",
        "            'tablas_folds': tablas_folds,     # lista de dataframes por fold\n",
        "            'df_metricas_comb': df_metricas_comb,\n",
        "            'df_summary_h': df_summary_h\n",
        "        }\n",
        "\n",
        "    df_comparativa = pd.DataFrame(comparativa_resumen).sort_values('n_lag').reset_index(drop=True)\n",
        "    return todos_lags, df_comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "91DpP6ZnMQTD",
      "metadata": {
        "id": "91DpP6ZnMQTD",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Funciones de plotting\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "def escoger_folds_por_rmse(resultados):\n",
        "    \"\"\"\n",
        "    Recibe lista de resultados (cada uno con 'rmse_test_prom').\n",
        "    Devuelve indices best (min rmse), worst (max rmse) y median (por valor).\n",
        "    \"\"\"\n",
        "    rmses = [r['rmse_test_prom'] for r in resultados]\n",
        "    order = np.argsort(rmses)\n",
        "    best_idx = int(order[0])\n",
        "    worst_idx = int(order[-1])\n",
        "    median_pos = int(len(order)//2)\n",
        "    median_idx = int(order[median_pos])\n",
        "    return best_idx, median_idx, worst_idx\n",
        "\n",
        "\n",
        "def plot_series_fold(resultados_fold, fold_idx, n_steps_input, title_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Grafica las series reales y predichas para un fold espec√≠fico.\n",
        "    \"\"\"\n",
        "    y_train_real = resultados_fold['y_train_real']\n",
        "    y_train_pred = resultados_fold['y_train_pred']\n",
        "    y_val_real   = resultados_fold['y_val_real']\n",
        "    y_val_pred   = resultados_fold['y_val_pred']\n",
        "    y_test_real  = resultados_fold['y_test_real']\n",
        "    y_test_pred  = resultados_fold['y_test_pred']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    # Entrenamiento\n",
        "    ax.plot(y_train_real[:, 0], label='Train Real', color='tab:blue', alpha=0.6)\n",
        "    ax.plot(y_train_pred[:, 0], label='Train Predicho', color='tab:cyan', linestyle='--', alpha=0.8)\n",
        "\n",
        "    # Validaci√≥n\n",
        "    ax.plot(range(len(y_train_real), len(y_train_real)+len(y_val_real)),\n",
        "             y_val_real[:, 0], label='Val Real', color='tab:orange', alpha=0.6)\n",
        "    ax.plot(range(len(y_train_real), len(y_train_real)+len(y_val_pred)),\n",
        "             y_val_pred[:, 0], label='Val Predicho', color='tab:red', linestyle='--', alpha=0.8)\n",
        "\n",
        "    # Test\n",
        "    ax.plot(range(len(y_train_real)+len(y_val_real),\n",
        "                  len(y_train_real)+len(y_val_real)+len(y_test_real)),\n",
        "             y_test_real[:, 0], label='Test Real', color='tab:green', alpha=0.6)\n",
        "    ax.plot(range(len(y_train_real)+len(y_val_real),\n",
        "                  len(y_train_real)+len(y_val_real)+len(y_test_pred)),\n",
        "             y_test_pred[:, 0], label='Test Predicho', color='tab:purple', linestyle='--', alpha=0.8)\n",
        "\n",
        "    ax.set_title(f\"{title_prefix} | Fold {fold_idx+1} | Ventana = {n_steps_input}\")\n",
        "    ax.set_xlabel(\"Tiempo\")\n",
        "    ax.set_ylabel(\"Valor (Volatilidad o Precio)\")\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_rmse_bars(resultados, n_steps_input):\n",
        "    \"\"\"\n",
        "    Grafica barras con el RMSE promedio por fold.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    rmses = [r['rmse_test_prom'] for r in resultados]\n",
        "    folds = np.arange(1, len(rmses)+1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.bar(folds, rmses, color='skyblue', edgecolor='k')\n",
        "    ax.set_title(f\"RMSE por Fold | Ventana = {n_steps_input}\")\n",
        "    ax.set_xlabel(\"Fold\")\n",
        "    ax.set_ylabel(\"RMSE promedio (test)\")\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for i, v in enumerate(rmses):\n",
        "        ax.text(folds[i], v, f\"{v:.3f}\", ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_rmse_promedio_por_horizonte(df_summary_h, n_steps_input):\n",
        "    \"\"\"\n",
        "    Muestra el RMSE promedio (y std si existe) por horizonte.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "    ax.plot(df_summary_h.index, df_summary_h['RMSE_mean'], marker='o', label='RMSE promedio')\n",
        "\n",
        "    if 'RMSE_std' in df_summary_h.columns:\n",
        "        ax.fill_between(df_summary_h.index,\n",
        "                        df_summary_h['RMSE_mean'] - df_summary_h['RMSE_std'],\n",
        "                        df_summary_h['RMSE_mean'] + df_summary_h['RMSE_std'],\n",
        "                        color='blue', alpha=0.2, label='Desviaci√≥n est√°ndar')\n",
        "\n",
        "    ax.set_title(f\"RMSE promedio por horizonte | Ventana = {n_steps_input}\")\n",
        "    ax.set_xlabel(\"Horizonte de predicci√≥n (h)\")\n",
        "    ax.set_ylabel(\"RMSE\")\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "64q0ICIyMQQY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64q0ICIyMQQY",
        "outputId": "ab97ff98-048f-44cd-b560-a029ef1ea823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Procesando n_lag = 7 ===\n",
            "Fold 1: train (325, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 2: train (324, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 3: train (323, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 4: train (322, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 5: train (324, 98) -> val (108, 98) -> test (108, 98)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Fold 1 | RMSE prom: 0.0608 | pval(h1): 0.9726225439211883\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Fold 2 | RMSE prom: 0.0728 | pval(h1): 0.0038120368733828964\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Fold 3 | RMSE prom: 0.0657 | pval(h1): 0.12480855191333039\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Fold 4 | RMSE prom: 0.0675 | pval(h1): 0.9244531506441696\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step \n",
            "Fold 5 | RMSE prom: 0.0599 | pval(h1): 0.6109352361485884\n",
            "\n",
            "=== Procesando n_lag = 14 ===\n",
            "Fold 1: train (172, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 2: train (171, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 3: train (170, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 4: train (169, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 5: train (168, 196) -> val (57, 196) -> test (56, 196)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Fold 1 | RMSE prom: 0.0633 | pval(h1): 0.8443107142443242\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Fold 2 | RMSE prom: 0.0696 | pval(h1): 0.8965439873263408\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Fold 3 | RMSE prom: 0.0642 | pval(h1): 0.8342902284984159\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 4 | RMSE prom: 0.0568 | pval(h1): 0.8749928916929897\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Fold 5 | RMSE prom: 0.0753 | pval(h1): 0.12749293251803878\n",
            "\n",
            "=== Procesando n_lag = 21 ===\n",
            "Fold 1: train (115, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 2: train (114, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 3: train (113, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 4: train (112, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 5: train (114, 294) -> val (38, 294) -> test (38, 294)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Fold 1 | RMSE prom: 0.1167 | pval(h1): 0.9640894030474525\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Fold 2 | RMSE prom: 0.1492 | pval(h1): 0.9837531640206383\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Fold 3 | RMSE prom: 0.0989 | pval(h1): 0.31208978180527874\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Fold 4 | RMSE prom: 0.0908 | pval(h1): 0.5118251309967707\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Fold 5 | RMSE prom: 0.0746 | pval(h1): 0.042031962480737886\n",
            "\n",
            "=== Procesando n_lag = 28 ===\n",
            "Fold 1: train (88, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 2: train (87, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 3: train (86, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 4: train (85, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 5: train (84, 392) -> val (29, 392) -> test (29, 392)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "Fold 1 | RMSE prom: 0.0813 | pval(h1): 0.8064781768019567\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 68ms/stepWARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018A06F10540> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "Fold 2 | RMSE prom: 0.0927 | pval(h1): 0.6872334199745156\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018A0D130400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Fold 3 | RMSE prom: 0.0887 | pval(h1): 0.6153989157671537\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Fold 4 | RMSE prom: 0.1014 | pval(h1): 0.24625813865271337\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Fold 5 | RMSE prom: 0.0924 | pval(h1): 0.772541283974989\n"
          ]
        }
      ],
      "source": [
        "# 1) Ejecutar evaluaci√≥n completa\n",
        "todos_lags, df_comparativa = evaluar_y_reportar(timeSeries, lags_list=[7,14,21,28],\n",
        "                                                n_outputs=7, epochs=80, batch_size=32,\n",
        "                                                verbose_fit=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c22d131",
      "metadata": {},
      "source": [
        "En la etapa de modelado de volatilidad, se evalu√≥ el desempe√±o del modelo bajo diferentes configuraciones de retardos temporales (7, 14, 21 y 28 d√≠as). Los resultados muestran un comportamiento estable para horizontes cortos, con valores promedio de RMSE entre 0.06 y 0.07 para los modelos con 7 y 14 lags, indicando una adecuada capacidad del modelo para capturar la variabilidad de corto plazo en la serie.\n",
        "\n",
        "A medida que se incrementa la ventana de rezagos (21 y 28 d√≠as), se observa un aumento gradual del error (RMSE entre 0.09 y 0.11), lo que sugiere una p√©rdida de precisi√≥n debido a la menor cantidad de datos efectivos para el entrenamiento y la posible diluci√≥n de patrones recientes. Los valores del p-valor del test BDS en la mayor√≠a de los pliegues superan el umbral de significancia (p > 0.05), lo que sugiere que los residuales no presentan dependencias no lineales relevantes, respaldando la validez del modelo en t√©rminos de independencia temporal.\n",
        "\n",
        "En general, el modelo logra una representaci√≥n coherente del comportamiento din√°mico de la volatilidad, especialmente en horizontes cortos, donde la memoria reciente del mercado parece ser m√°s informativa para la predicci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffba99e9",
      "metadata": {},
      "source": [
        "### *Tabla de Resumen Comparativo por Lags*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f4bQ0sDpNzyo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "f4bQ0sDpNzyo",
        "outputId": "d6db3b77-2895-4d9d-9f71-2c93cf01b049"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_lag</th>\n",
              "      <th>RMSE_prom</th>\n",
              "      <th>RMSE_std</th>\n",
              "      <th>MAE_prom</th>\n",
              "      <th>MAPE_prom</th>\n",
              "      <th>MSE_prom</th>\n",
              "      <th>BDS_pvalue_h1_prom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0.065362</td>\n",
              "      <td>0.013288</td>\n",
              "      <td>0.041183</td>\n",
              "      <td>7.329915</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.527326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.065832</td>\n",
              "      <td>0.012181</td>\n",
              "      <td>0.044774</td>\n",
              "      <td>7.851903</td>\n",
              "      <td>0.004801</td>\n",
              "      <td>0.715526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0.106048</td>\n",
              "      <td>0.033549</td>\n",
              "      <td>0.067084</td>\n",
              "      <td>11.853536</td>\n",
              "      <td>0.013734</td>\n",
              "      <td>0.562758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>0.091302</td>\n",
              "      <td>0.021816</td>\n",
              "      <td>0.067386</td>\n",
              "      <td>12.319823</td>\n",
              "      <td>0.009229</td>\n",
              "      <td>0.625582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_lag  RMSE_prom  RMSE_std  MAE_prom  MAPE_prom  MSE_prom  \\\n",
              "0      7   0.065362  0.013288  0.041183   7.329915  0.004664   \n",
              "1     14   0.065832  0.012181  0.044774   7.851903  0.004801   \n",
              "2     21   0.106048  0.033549  0.067084  11.853536  0.013734   \n",
              "3     28   0.091302  0.021816  0.067386  12.319823  0.009229   \n",
              "\n",
              "   BDS_pvalue_h1_prom  \n",
              "0            0.527326  \n",
              "1            0.715526  \n",
              "2            0.562758  \n",
              "3            0.625582  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2) Ver tabla resumen comparativa de los 4 lags:\n",
        "df_comparativa.to_csv(r'C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\tablas\\resumen_comparativo.csv', index=False)\n",
        "df_comparativa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbaa461",
      "metadata": {},
      "source": [
        "Los resultados del modelo para la predicci√≥n de volatilidad del Bitcoin muestran un desempe√±o estable y coherente a trav√©s de las distintas configuraciones de retardos. Los menores errores promedio se observan con lags de 7 y 14 d√≠as, con valores de RMSE ‚âà 0.065 y MAE ‚âà 0.04‚Äì0.045, lo que evidencia una buena capacidad del modelo para capturar la din√°mica de corto plazo.\n",
        "\n",
        "En cambio, al incrementar la memoria temporal (lags de 21 y 28 d√≠as), los errores aumentan ligeramente (RMSE entre 0.09 y 0.11), lo que sugiere que incluir retardos m√°s largos introduce ruido o patrones menos relevantes para la predicci√≥n inmediata.\n",
        "\n",
        "El MAPE, que se mantiene entre 7% y 12%, refuerza la estabilidad general del modelo en t√©rminos relativos.\n",
        "Finalmente, los valores del p-valor del test BDS (entre 0.52 y 0.71) superan el umbral de significancia (0.05), indicando que los residuales no presentan dependencias no lineales, por lo que el modelo logra capturar adecuadamente la estructura temporal de la volatilidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "q9gQHPmZNzxR",
      "metadata": {
        "id": "q9gQHPmZNzxR",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def resultados_lag_vol(n_lag):\n",
        "    # 3) Para un lag espec√≠fico:\n",
        "    info = todos_lags[n_lag]\n",
        "    resultados = info['resultados']   # lista por fold\n",
        "    tablas_folds = info['tablas_folds']\n",
        "    df_metricas_comb = info['df_metricas_comb']\n",
        "    df_summary_h = info['df_summary_h']\n",
        "\n",
        "    # Crear carpetas si no existen\n",
        "    base_dir = fr'C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad'\n",
        "    tablas_dir = os.path.join(base_dir, 'tablas', f'lag_{n_lag}')\n",
        "    figs_dir = os.path.join(base_dir, 'figs', f'lag_{n_lag}')\n",
        "    os.makedirs(tablas_dir, exist_ok=True)\n",
        "    os.makedirs(figs_dir, exist_ok=True)\n",
        "\n",
        "    # 4) Guardar tablas por fold (test)\n",
        "    for i, df in enumerate(tablas_folds):\n",
        "        print(f\"\\n--- Fold {i+1} ---\")\n",
        "        df_path = os.path.join(tablas_dir, f'fold_{i+1}_lag_{n_lag}.csv')\n",
        "        df.to_csv(df_path, index=False)\n",
        "        print(df)\n",
        "\n",
        "    # 5) Seleccionar best/median/worst y plotear\n",
        "    best, med, worst = escoger_folds_por_rmse(resultados)\n",
        "\n",
        "    # Mejor\n",
        "    fig = plot_series_fold(resultados[best], best, n_steps_input=n_lag, title_prefix=\"Mejor (RMSE)\")\n",
        "    fig.savefig(os.path.join(figs_dir, f'mejor_rmse_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Mediano\n",
        "    fig = plot_series_fold(resultados[med], med, n_steps_input=n_lag, title_prefix=\"Mediano (RMSE)\")\n",
        "    fig.savefig(os.path.join(figs_dir, f'mediano_rmse_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Peor\n",
        "    fig = plot_series_fold(resultados[worst], worst, n_steps_input=n_lag, title_prefix=\"Peor (RMSE)\")\n",
        "    fig.savefig(os.path.join(figs_dir, f'peor_rmse_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # 6) Gr√°ficas adicionales\n",
        "    fig = plot_rmse_bars(resultados, n_steps_input=n_lag)\n",
        "    fig.savefig(os.path.join(figs_dir, f'rmse_por_fold_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = plot_rmse_promedio_por_horizonte(df_summary_h, n_steps_input=n_lag)\n",
        "    fig.savefig(os.path.join(figs_dir, f'rmse_promedio_por_horizonte_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    print(f\"\\n‚úÖ Resultados y gr√°ficas guardados en: {figs_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42ee12f8",
      "metadata": {},
      "source": [
        "### *Tablas de Metricas: Resumen por Horizonte y por Fold*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a4dzre1PNzqn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4dzre1PNzqn",
        "outputId": "985b3203-375f-4116-84b5-7a5f8b91756f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE      MAPE  BDS_pvalue_h1\n",
            "0         1  0.030249  0.007049  0.083957  5.779067       0.972623\n",
            "1         2  0.043901  0.005275  0.072630  7.506183            NaN\n",
            "2         3  0.034280  0.002521  0.050206  6.096272            NaN\n",
            "3         4  0.045353  0.007061  0.084029  7.114623            NaN\n",
            "4         5  0.039249  0.003304  0.057479  6.677889            NaN\n",
            "5         6  0.023782  0.001292  0.035941  3.641690            NaN\n",
            "6         7  0.024639  0.001716  0.041430  3.870203            NaN\n",
            "7  Promedio  0.034493  0.004031  0.060810  5.812275            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.046059  0.005721  0.075637   8.910223       0.003812\n",
            "1         2  0.041705  0.003771  0.061411   7.477346            NaN\n",
            "2         3  0.050156  0.005986  0.077371   9.099414            NaN\n",
            "3         4  0.050253  0.008036  0.089645   8.129569            NaN\n",
            "4         5  0.056413  0.005106  0.071459  10.627784            NaN\n",
            "5         6  0.039936  0.004155  0.064457   7.045009            NaN\n",
            "6         7  0.039760  0.004888  0.069911   6.139690            NaN\n",
            "7  Promedio  0.046326  0.005380  0.072841   8.204148            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.035617  0.002099  0.045813   6.694649       0.124809\n",
            "1         2  0.038936  0.003217  0.056719   6.663948            NaN\n",
            "2         3  0.047235  0.007110  0.084319   8.137744            NaN\n",
            "3         4  0.056895  0.009226  0.096053  10.904566            NaN\n",
            "4         5  0.043064  0.002803  0.052943   7.975056            NaN\n",
            "5         6  0.035791  0.002569  0.050689   7.121317            NaN\n",
            "6         7  0.039855  0.005422  0.073638   7.861831            NaN\n",
            "7  Promedio  0.042485  0.004635  0.065739   7.908444            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.040056  0.002763  0.052563   7.533560       0.924453\n",
            "1         2  0.044227  0.004066  0.063766   7.748323            NaN\n",
            "2         3  0.059914  0.010141  0.100702   9.378470            NaN\n",
            "3         4  0.064858  0.008371  0.091493  12.582550            NaN\n",
            "4         5  0.049014  0.004175  0.064616   9.346686            NaN\n",
            "5         6  0.036086  0.002720  0.052151   6.655907            NaN\n",
            "6         7  0.036022  0.002247  0.047403   6.933674            NaN\n",
            "7  Promedio  0.047168  0.004926  0.067528   8.597024            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.023813  0.001140  0.033757   3.784807       0.610935\n",
            "1         2  0.037416  0.005668  0.075285   5.696678            NaN\n",
            "2         3  0.052657  0.014509  0.120452  10.190966            NaN\n",
            "3         4  0.040731  0.003043  0.055164   7.485755            NaN\n",
            "4         5  0.037614  0.002328  0.048245   6.750220            NaN\n",
            "5         6  0.026777  0.001572  0.039647   4.282890            NaN\n",
            "6         7  0.029092  0.002180  0.046693   4.702469            NaN\n",
            "7  Promedio  0.035443  0.004348  0.059892   6.127684            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_7\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "016CwUJUNzoD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "016CwUJUNzoD",
        "outputId": "78cc3c19-2dbf-4162-e2e6-4ba414cc0980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.037811  0.005012  0.070799   6.202642       0.844311\n",
            "1         2  0.028294  0.001260  0.035497   5.244955            NaN\n",
            "2         3  0.043389  0.003150  0.056129   7.719710            NaN\n",
            "3         4  0.052653  0.003948  0.062832   8.981543            NaN\n",
            "4         5  0.057342  0.006394  0.079962  10.725668            NaN\n",
            "5         6  0.042420  0.005792  0.076102   7.349739            NaN\n",
            "6         7  0.040714  0.003824  0.061842   6.822726            NaN\n",
            "7  Promedio  0.043232  0.004197  0.063309   7.578141            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.042202  0.005545  0.074467   6.836543       0.896544\n",
            "1         2  0.035416  0.002589  0.050885   5.541851            NaN\n",
            "2         3  0.044371  0.002886  0.053723   7.813528            NaN\n",
            "3         4  0.064968  0.007465  0.086399  10.686930            NaN\n",
            "4         5  0.057685  0.005167  0.071884  11.315058            NaN\n",
            "5         6  0.047510  0.006400  0.079998   8.506147            NaN\n",
            "6         7  0.043201  0.004846  0.069615   7.979889            NaN\n",
            "7  Promedio  0.047908  0.004986  0.069567   8.382849            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.042098  0.005325  0.072973   7.003447        0.83429\n",
            "1         2  0.036241  0.004065  0.063757   5.710135            NaN\n",
            "2         3  0.038996  0.002381  0.048800   7.047998            NaN\n",
            "3         4  0.045667  0.003608  0.060066   7.295222            NaN\n",
            "4         5  0.056422  0.008287  0.091035  10.103897            NaN\n",
            "5         6  0.037270  0.003062  0.055338   6.563032            NaN\n",
            "6         7  0.039631  0.003320  0.057621   7.071829            NaN\n",
            "7  Promedio  0.042332  0.004293  0.064227   7.256509            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.038087  0.003230  0.056831   6.325436       0.874993\n",
            "1         2  0.030043  0.001955  0.044215   4.751195            NaN\n",
            "2         3  0.036906  0.002124  0.046087   6.532923            NaN\n",
            "3         4  0.052111  0.005264  0.072552   8.159190            NaN\n",
            "4         5  0.053211  0.005327  0.072987  10.027335            NaN\n",
            "5         6  0.041472  0.003929  0.062680   7.392155            NaN\n",
            "6         7  0.033902  0.001760  0.041956   6.181576            NaN\n",
            "7  Promedio  0.040819  0.003370  0.056758   7.052830            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.036312  0.002686  0.051823   5.893852       0.127493\n",
            "1         2  0.038836  0.002412  0.049108   6.393380            NaN\n",
            "2         3  0.067324  0.011402  0.106782  12.335210            NaN\n",
            "3         4  0.083059  0.024074  0.155157  15.818485            NaN\n",
            "4         5  0.055177  0.005445  0.073793  10.214339            NaN\n",
            "5         6  0.033343  0.002169  0.046572   6.290333            NaN\n",
            "6         7  0.032998  0.001925  0.043870   5.978703            NaN\n",
            "7  Promedio  0.049578  0.007159  0.075301   8.989186            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_14\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "gCs1V7d0Nzkx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gCs1V7d0Nzkx",
        "outputId": "0a494676-7714-452c-c937-74f11231b829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.077957  0.032422  0.180062  12.593175       0.964089\n",
            "1         2  0.067619  0.010725  0.103564  12.297044            NaN\n",
            "2         3  0.053323  0.005750  0.075828  10.024552            NaN\n",
            "3         4  0.077096  0.009398  0.096944  13.713713            NaN\n",
            "4         5  0.056913  0.006028  0.077639  11.303682            NaN\n",
            "5         6  0.077572  0.022261  0.149200  11.226348            NaN\n",
            "6         7  0.076992  0.017898  0.133783  11.157223            NaN\n",
            "7  Promedio  0.069639  0.014926  0.116717  11.759391            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.096223  0.048659  0.220589  14.411435       0.983753\n",
            "1         2  0.071902  0.008267  0.090921  13.549644            NaN\n",
            "2         3  0.074091  0.009713  0.098557  13.251196            NaN\n",
            "3         4  0.080351  0.010989  0.104827  16.965065            NaN\n",
            "4         5  0.048415  0.005018  0.070835   8.230505            NaN\n",
            "5         6  0.137493  0.061360  0.247709  22.971930            NaN\n",
            "6         7  0.096327  0.044551  0.211071  13.683785            NaN\n",
            "7  Promedio  0.086400  0.026937  0.149216  14.723366            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.071139  0.008713  0.093345  12.857806        0.31209\n",
            "1         2  0.057325  0.005683  0.075388  10.319202            NaN\n",
            "2         3  0.057493  0.005289  0.072723  10.804247            NaN\n",
            "3         4  0.066823  0.009140  0.095604  13.601635            NaN\n",
            "4         5  0.038682  0.002207  0.046979   7.396983            NaN\n",
            "5         6  0.081567  0.024481  0.156465  13.432070            NaN\n",
            "6         7  0.082503  0.023005  0.151673  12.861175            NaN\n",
            "7  Promedio  0.065076  0.011217  0.098882  11.610446            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.076200  0.012534  0.111957  14.801406       0.511825\n",
            "1         2  0.058864  0.006515  0.080715  10.840321            NaN\n",
            "2         3  0.049545  0.003862  0.062149   9.476916            NaN\n",
            "3         4  0.047396  0.003537  0.059475   8.620012            NaN\n",
            "4         5  0.041186  0.003203  0.056593   8.128917            NaN\n",
            "5         6  0.066384  0.007615  0.087264  12.938076            NaN\n",
            "6         7  0.078940  0.031545  0.177610  11.435928            NaN\n",
            "7  Promedio  0.059788  0.009830  0.090823  10.891654            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.047633  0.004652  0.068204   8.172714       0.042032\n",
            "1         2  0.045026  0.004126  0.064233   8.290924            NaN\n",
            "2         3  0.057023  0.009713  0.098555   9.348131            NaN\n",
            "3         4  0.042201  0.002934  0.054168   7.248882            NaN\n",
            "4         5  0.054547  0.004770  0.069064  11.634895            NaN\n",
            "5         6  0.065288  0.006443  0.080269  12.919632            NaN\n",
            "6         7  0.069887  0.007693  0.087709  14.364581            NaN\n",
            "7  Promedio  0.054515  0.005761  0.074600  10.282823            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_21\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "vK58Cru9PGqF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vK58Cru9PGqF",
        "outputId": "bfdb99b0-7845-40b4-8963-1b4c02d6546c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.081712  0.009565  0.097798  14.655980       0.806478\n",
            "1         2  0.051507  0.004923  0.070163   7.833900            NaN\n",
            "2         3  0.054528  0.005173  0.071923  14.396486            NaN\n",
            "3         4  0.045017  0.003361  0.057974   8.445345            NaN\n",
            "4         5  0.079491  0.011951  0.109321  14.419879            NaN\n",
            "5         6  0.059341  0.005023  0.070872  11.185952            NaN\n",
            "6         7  0.070665  0.008345  0.091351  11.582158            NaN\n",
            "7  Promedio  0.063180  0.006906  0.081343  11.788529            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.080551  0.012601  0.112255  14.961220       0.687233\n",
            "1         2  0.055530  0.003958  0.062916   9.075311            NaN\n",
            "2         3  0.064450  0.005783  0.076043  14.515606            NaN\n",
            "3         4  0.049395  0.004821  0.069433   9.971223            NaN\n",
            "4         5  0.069832  0.010359  0.101779  14.915786            NaN\n",
            "5         6  0.101537  0.015233  0.123424  19.398230            NaN\n",
            "6         7  0.087589  0.010585  0.102883  15.570782            NaN\n",
            "7  Promedio  0.072698  0.009049  0.092676  14.058308            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.098565  0.017175  0.131055  17.295720       0.615399\n",
            "1         2  0.075186  0.012169  0.110312  11.248959            NaN\n",
            "2         3  0.037488  0.002029  0.045043   7.286609            NaN\n",
            "3         4  0.051848  0.003847  0.062026  10.174272            NaN\n",
            "4         5  0.059877  0.006242  0.079005  12.033740            NaN\n",
            "5         6  0.088542  0.011590  0.107657  16.220474            NaN\n",
            "6         7  0.065754  0.007381  0.085911  11.745066            NaN\n",
            "7  Promedio  0.068180  0.008633  0.088715  12.286406            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.083390  0.012311  0.110956  17.404378       0.246258\n",
            "1         2  0.054998  0.005598  0.074817  10.204173            NaN\n",
            "2         3  0.050385  0.003886  0.062341   9.522094            NaN\n",
            "3         4  0.062268  0.007160  0.084618  11.078237            NaN\n",
            "4         5  0.112052  0.040426  0.201063  18.121277            NaN\n",
            "5         6  0.065799  0.009054  0.095151  12.562179            NaN\n",
            "6         7  0.062079  0.006497  0.080606  11.218787            NaN\n",
            "7  Promedio  0.070139  0.012133  0.101365  12.873018            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.061383  0.011064  0.105185   9.913480       0.772541\n",
            "1         2  0.049753  0.004746  0.068894   9.189818            NaN\n",
            "2         3  0.033054  0.001737  0.041682   6.373313            NaN\n",
            "3         4  0.065941  0.006189  0.078669  11.245221            NaN\n",
            "4         5  0.098890  0.017227  0.131250  16.444463            NaN\n",
            "5         6  0.070923  0.016173  0.127172  11.371909            NaN\n",
            "6         7  0.059193  0.008838  0.094009   9.611784            NaN\n",
            "7  Promedio  0.062734  0.009425  0.092409  10.592856            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_28\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(28)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
