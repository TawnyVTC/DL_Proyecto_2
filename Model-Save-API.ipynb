{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d7ae2a77",
      "metadata": {
        "id": "d7ae2a77"
      },
      "source": [
        "# **Modelado: Volatilidad**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "11cf53c0",
      "metadata": {
        "id": "11cf53c0",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e3a535a4",
      "metadata": {
        "id": "e3a535a4",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "btc = pd.read_csv(r'https://raw.githubusercontent.com/TawnyVTC/Proyectos_UN/refs/heads/main/2025/Deep_Learning/Data/btc_1d_with_volatility_and_lags.csv')\n",
        "btc['Open time'] = pd.to_datetime(btc['Open time'], format='%Y-%m-%d')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e75XJV58q1XK",
      "metadata": {
        "id": "e75XJV58q1XK"
      },
      "source": [
        "## **Split Temporal y Validaci√≥n Cruzada**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d77354",
      "metadata": {},
      "source": [
        "En esta secci√≥n se replica la misma l√≥gica empleada para la predicci√≥n del precio de cierre, pero enfocada en la volatilidad del Bitcoin. Primero, se generan variables retardadas de la volatilidad (lags de 7, 14, 21 y 28 d√≠as), que capturan la dependencia temporal del indicador y permiten al modelo aprender patrones hist√≥ricos. Posteriormente, se crean los objetivos futuros correspondientes a los pr√≥ximos siete d√≠as (t+1 a t+7), de modo que el modelo pueda realizar predicciones multihorizonte.\n",
        "\n",
        "Las caracter√≠sticas de entrada incluyen tanto variables del precio (Close, LogReturn) como las medidas de volatilidad actual y retardada, buscando combinar informaci√≥n de nivel y dispersi√≥n. Finalmente, se eliminan los valores faltantes generados por los desplazamientos y se construyen las matrices de entrada (X) y salida (y) que alimentar√°n el flujo principal de entrenamiento, conformando el objeto timeSeries con el que se aplicar√°n los mismos experimentos de evaluaci√≥n por n√∫mero de lags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0430259",
      "metadata": {
        "id": "d0430259"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# 1. Crear lags de volatilidad\n",
        "# -----------------------\n",
        "for lag in [7, 14, 21, 28]:\n",
        "    btc[f'Volatility_lag_{lag}'] = btc['Volatility'].shift(lag)\n",
        "\n",
        "# -----------------------\n",
        "# 2. Crear targets futuros (predicciones de volatilidad)\n",
        "# -----------------------\n",
        "for i in range(1, 8):  # t+1 a t+7\n",
        "    btc[f'target_vol_t+{i}'] = btc['Volatility'].shift(-i)\n",
        "\n",
        "# -----------------------\n",
        "# 3. Definir features y targets\n",
        "# -----------------------\n",
        "features = [\n",
        "    'Close', 'LogReturn', 'Volatility',\n",
        "    'Volatility_lag_7', 'Volatility_lag_14', 'Volatility_lag_21', 'Volatility_lag_28'\n",
        "]\n",
        "\n",
        "targets = [f'target_vol_t+{i}' for i in range(1, 8)]\n",
        "\n",
        "# -----------------------\n",
        "# 4. Eliminar filas con NaN (por los shifts)\n",
        "# -----------------------\n",
        "btc = btc.dropna(subset=features + targets).reset_index(drop=True)\n",
        "\n",
        "# -----------------------\n",
        "# 5. Definir matrices de entrada y salida\n",
        "# -----------------------\n",
        "X = btc[features].values\n",
        "y = btc[targets].values\n",
        "dates = btc[\"Open time\"].values\n",
        "\n",
        "# -----------------------\n",
        "# 6. Construcci√≥n del objeto timeSeries\n",
        "# -----------------------\n",
        "timeSeries = np.concatenate([X, y], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1243fb76",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Gr2anZEbq-Yh",
      "metadata": {
        "id": "Gr2anZEbq-Yh",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from tsxv.splitTrainValTest import split_train_val_test_groupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def _ensure_2d(arr):\n",
        "    \"\"\"\n",
        "    Convierte el array a formato 2D.\n",
        "    Si llega 1D ‚Üí (n,1); si llega 3D ‚Üí (n, timesteps*feats)\n",
        "    \"\"\"\n",
        "    arr = np.asarray(arr)\n",
        "    if arr.ndim == 1:\n",
        "        return arr.reshape(-1, 1)\n",
        "    if arr.ndim == 2:\n",
        "        return arr\n",
        "    if arr.ndim == 3:\n",
        "        n, a, b = arr.shape\n",
        "        return arr.reshape(n, a * b)\n",
        "    raise ValueError(f\"Array con ndim={arr.ndim} no soportado por esta funci√≥n.\")\n",
        "\n",
        "\n",
        "def split_and_scale(timeSeries, n_steps_input=7, n_steps_forecast=7, n_steps_jump=1, target_col=2):\n",
        "    X_list, y_list, Xcv_list, ycv_list, Xtest_list, ytest_list = split_train_val_test_groupKFold(\n",
        "        timeSeries,\n",
        "        n_steps_input,\n",
        "        n_steps_forecast,\n",
        "        n_steps_jump\n",
        "    )\n",
        "\n",
        "    X_train_scaled, X_val_scaled, X_test_scaled = [], [], []\n",
        "    y_train_scaled, y_val_scaled, y_test_scaled = [], [], []\n",
        "    scalers_x, scalers_y = [], []\n",
        "\n",
        "    for fold in range(len(X_list)):\n",
        "        X_train_raw = _ensure_2d(X_list[fold])\n",
        "        X_val_raw   = _ensure_2d(Xcv_list[fold])\n",
        "        X_test_raw  = _ensure_2d(Xtest_list[fold])\n",
        "\n",
        "        # üëá Aqu√≠ filtramos solo la variable objetivo (columna target)\n",
        "        y_train_raw = _ensure_2d(y_list[fold])[:, target_col:target_col + n_steps_forecast]\n",
        "        y_val_raw   = _ensure_2d(ycv_list[fold])[:, target_col:target_col + n_steps_forecast]\n",
        "        y_test_raw  = _ensure_2d(ytest_list[fold])[:, target_col:target_col + n_steps_forecast]\n",
        "\n",
        "        # Escaladores\n",
        "        scaler_x = StandardScaler().fit(X_train_raw)\n",
        "        scaler_y = StandardScaler().fit(y_train_raw)\n",
        "\n",
        "        X_train_scaled.append(scaler_x.transform(X_train_raw))\n",
        "        X_val_scaled.append(scaler_x.transform(X_val_raw))\n",
        "        X_test_scaled.append(scaler_x.transform(X_test_raw))\n",
        "        y_train_scaled.append(scaler_y.transform(y_train_raw))\n",
        "        y_val_scaled.append(scaler_y.transform(y_val_raw))\n",
        "        y_test_scaled.append(scaler_y.transform(y_test_raw))\n",
        "\n",
        "        scalers_x.append(scaler_x)\n",
        "        scalers_y.append(scaler_y)\n",
        "\n",
        "        print(f\"Fold {fold+1}: train {X_train_raw.shape} -> val {X_val_raw.shape} -> test {X_test_raw.shape}\")\n",
        "\n",
        "    return {\n",
        "        'X_train': X_train_scaled,\n",
        "        'X_val': X_val_scaled,\n",
        "        'X_test': X_test_scaled,\n",
        "        'y_train': y_train_scaled,\n",
        "        'y_val': y_val_scaled,\n",
        "        'y_test': y_test_scaled,\n",
        "        'scalers_x': scalers_x,\n",
        "        'scalers_y': scalers_y\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U1b8-yzuq71m",
      "metadata": {
        "id": "U1b8-yzuq71m"
      },
      "source": [
        "## **Modelado con Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e37fe85",
      "metadata": {
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "oLzRsaLeMG60",
      "metadata": {
        "id": "oLzRsaLeMG60",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "def test_independencia_residuos(residuos, lags=10):\n",
        "    resultado = acorr_ljungbox(residuos, lags=[lags], return_df=True)\n",
        "    return resultado['lb_pvalue'].iloc[0]\n",
        "\n",
        "def _calc_metrics_per_horizon(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true, y_pred: arrays (n_samples, n_horizons)\n",
        "    Devuelve DataFrame con m√©tricas por horizonte.\n",
        "    \"\"\"\n",
        "    n_outputs = y_true.shape[1]\n",
        "    rows = []\n",
        "    for h in range(n_outputs):\n",
        "        yt = y_true[:, h]\n",
        "        yp = y_pred[:, h]\n",
        "        mae = mean_absolute_error(yt, yp)\n",
        "        mse = mean_squared_error(yt, yp)\n",
        "        rmse = np.sqrt(mse)\n",
        "        # MAPE con epsilon para evitar divisi√≥n por cero\n",
        "        mape = np.mean(np.abs((yt - yp) / (np.abs(yt) + 1e-8))) * 100\n",
        "        rows.append({'Horizonte': h+1, 'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape})\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Q6FDl1KrMQbJ",
      "metadata": {
        "id": "Q6FDl1KrMQbJ",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def entrenar_mlp_folds(data_dict, n_outputs=7, epochs=100, batch_size=32, verbose_fit=0, lag=None, save_dir='models'):\n",
        "    \"\"\"\n",
        "    Entrena un modelo MLP para cada fold y guarda el mejor fold (seg√∫n RMSE promedio en test).\n",
        "\n",
        "    Par√°metros:\n",
        "    ------------\n",
        "    data_dict : dict\n",
        "        Diccionario con datos escalados (X_train, y_train, etc.)\n",
        "    n_outputs : int\n",
        "        N√∫mero de pasos de predicci√≥n (por defecto 7).\n",
        "    epochs : int\n",
        "        √âpocas de entrenamiento.\n",
        "    batch_size : int\n",
        "        Tama√±o del batch.\n",
        "    verbose_fit : int\n",
        "        Nivel de verbosidad del entrenamiento.\n",
        "    lag : int, opcional\n",
        "        N√∫mero de lag, usado para nombrar la carpeta de guardado.\n",
        "    save_dir : str\n",
        "        Carpeta base donde se guardar√°n los modelos.\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    resultados : list\n",
        "        Lista con resultados por fold (predicciones, m√©tricas, etc.)\n",
        "    tablas_folds : list\n",
        "        Lista de dataframes con m√©tricas por horizonte.\n",
        "    best_fold : int\n",
        "        √çndice del mejor fold (basado en RMSE promedio test).\n",
        "    \"\"\"\n",
        "\n",
        "    resultados = []\n",
        "    tablas_folds = []\n",
        "\n",
        "    for fold in range(len(data_dict['X_train'])):\n",
        "        print(f\"\\n===== Fold {fold+1}/{len(data_dict['X_train'])} =====\")\n",
        "\n",
        "        X_train, X_val, X_test = data_dict['X_train'][fold], data_dict['X_val'][fold], data_dict['X_test'][fold]\n",
        "        y_train, y_val, y_test = data_dict['y_train'][fold], data_dict['y_val'][fold], data_dict['y_test'][fold]\n",
        "        scaler_y = data_dict['scalers_y'][fold]\n",
        "\n",
        "        # --- Modelo ---\n",
        "        model = Sequential([\n",
        "            Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "            Dropout(0.2),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(n_outputs)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                  epochs=epochs, batch_size=batch_size, verbose=verbose_fit, callbacks=[es])\n",
        "\n",
        "        # --- Predicciones desescaladas ---\n",
        "        yhat_train = scaler_y.inverse_transform(model.predict(X_train))\n",
        "        yhat_val = scaler_y.inverse_transform(model.predict(X_val))\n",
        "        yhat_test = scaler_y.inverse_transform(model.predict(X_test))\n",
        "        ytrain_real = scaler_y.inverse_transform(y_train)\n",
        "        yval_real = scaler_y.inverse_transform(y_val)\n",
        "        ytest_real = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "        # --- M√©tricas ---\n",
        "        df_metrics = _calc_metrics_per_horizon(ytest_real, yhat_test)\n",
        "        promedio = df_metrics.mean(numeric_only=True).to_dict()\n",
        "        promedio['Horizonte'] = 'Promedio'\n",
        "        df_metrics = pd.concat([df_metrics, pd.DataFrame([promedio])], ignore_index=True)\n",
        "\n",
        "        # p-value BDS\n",
        "        resid_h1 = ytest_real[:, 0] - yhat_test[:, 0]\n",
        "        try:\n",
        "            pval = test_independencia_residuos(resid_h1, lags=10)\n",
        "        except Exception:\n",
        "            pval = np.nan\n",
        "\n",
        "        bds_col = [np.nan] * len(df_metrics)\n",
        "        if len(df_metrics) > 0:\n",
        "            bds_col[0] = pval\n",
        "        df_metrics['BDS_pvalue_h1'] = bds_col\n",
        "\n",
        "        rmse_prom = df_metrics.loc[df_metrics['Horizonte'] == 'Promedio', 'RMSE'].values[0]\n",
        "        print(f\"Fold {fold+1} | RMSE prom: {rmse_prom:.4f} | pval(h1): {pval}\")\n",
        "\n",
        "        resultados.append({\n",
        "            'fold': fold+1,\n",
        "            'rmse_test_prom': rmse_prom,\n",
        "            'pval_h1': pval,\n",
        "            'y_train_real': ytrain_real, 'y_train_pred': yhat_train,\n",
        "            'y_val_real': yval_real, 'y_val_pred': yhat_val,\n",
        "            'y_test_real': ytest_real, 'y_test_pred': yhat_test,\n",
        "            'df_metrics': df_metrics,\n",
        "            'model': model\n",
        "        })\n",
        "\n",
        "        tablas_folds.append(df_metrics)\n",
        "\n",
        "    # --- Seleccionar mejor fold ---\n",
        "    rmse_vals = [r['rmse_test_prom'] for r in resultados]\n",
        "    best_fold = int(np.argmin(rmse_vals))\n",
        "    best_model = resultados[best_fold]['model']\n",
        "    print(f\"\\n‚úÖ Mejor fold: {best_fold+1} con RMSE promedio {rmse_vals[best_fold]:.4f}\")\n",
        "\n",
        "    # --- Guardar modelo ---\n",
        "    if lag is not None:\n",
        "        model_dir = os.path.join(save_dir, f\"lag_{lag}\")\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        model_path = os.path.join(model_dir, f\"mejor_fold_lag_{lag}.keras\")\n",
        "        best_model.save(model_path)\n",
        "        print(f\"üíæ Modelo guardado en: {model_path}\")\n",
        "\n",
        "    return resultados, tablas_folds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "TcXxpG_zMQYb",
      "metadata": {
        "id": "TcXxpG_zMQYb",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Funciones para agregar resultados por lag y crear tablas resumen\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "def resumen_por_lag(tablas_folds):\n",
        "    \"\"\"\n",
        "    tablas_folds: lista de dataframes (uno por fold), cada df tiene las filas por horizonte + 'Promedio'.\n",
        "    Devuelve df resumen por horizonte con mean y std entre folds.\n",
        "    \"\"\"\n",
        "    # extraer solo filas de horizonte 1..H (no 'Promedio') para hacer stats por horizonte\n",
        "    # asumimos que todos los df tienen la misma cantidad de horizontes antes de la fila Promedio\n",
        "    list_horizon_dfs = []\n",
        "    for df in tablas_folds:\n",
        "        # seleccionar solo filas cuyo 'Horizonte' no sea 'Promedio'\n",
        "        df_h = df[df['Horizonte'] != 'Promedio'].copy()\n",
        "        df_h = df_h.reset_index(drop=True)\n",
        "        list_horizon_dfs.append(df_h)\n",
        "\n",
        "    # concatenar en multiindex: fold, horizonte\n",
        "    concat = pd.concat(list_horizon_dfs, keys=range(1, len(list_horizon_dfs)+1), names=['fold','row'])\n",
        "    # Queremos agrupar por horizonte y calcular mean/std de m√©tricas\n",
        "    metrics = ['MAPE','MAE','RMSE','MSE']\n",
        "    summary_rows = []\n",
        "    for h in sorted(concat['Horizonte'].unique(), key=lambda x: int(x)):\n",
        "        sel = concat[concat['Horizonte']==h]\n",
        "        row = {'Horizonte': int(h)}\n",
        "        for m in metrics:\n",
        "            row[f'{m}_mean'] = sel[m].mean()\n",
        "            row[f'{m}_std'] = sel[m].std()\n",
        "        # p-value mean across folds: buscar pval en fold df (est√° en la primera fila BDS_pvalue_h1)\n",
        "        # coletar pvals\n",
        "        pvals = []\n",
        "        for df in tablas_folds:\n",
        "            pv = df['BDS_pvalue_h1'].iloc[0]\n",
        "            if not np.isnan(pv):\n",
        "                pvals.append(pv)\n",
        "        row['BDS_pvalue_h1_mean'] = np.mean(pvals) if len(pvals)>0 else np.nan\n",
        "        row['BDS_pvalue_h1_std'] = np.std(pvals) if len(pvals)>0 else np.nan\n",
        "\n",
        "        summary_rows.append(row)\n",
        "\n",
        "    df_summary = pd.DataFrame(summary_rows)\n",
        "    return df_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "tYkQZDkBMQVp",
      "metadata": {
        "id": "tYkQZDkBMQVp",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Funci√≥n principal: eval√∫a lista de lags y devuelve todo lo necesario\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "def evaluar_y_reportar(timeSeries, lags_list=[7,14,21,28], n_outputs=7,\n",
        "                        epochs=80, batch_size=32, verbose_fit=0):\n",
        "    \"\"\"\n",
        "    Ejecuta todo el flujo para cada n_lag:\n",
        "    - split + scale\n",
        "    - entrenar por folds\n",
        "    - guarda tablas por fold y resumen por lag (mean + std)\n",
        "    - devuelve estructura con todo para plotting y tablas\n",
        "    \"\"\"\n",
        "    todos_lags = {}\n",
        "    comparativa_resumen = []\n",
        "\n",
        "    for n_lag in lags_list:\n",
        "        print(f\"\\n=== Procesando n_lag = {n_lag} ===\")\n",
        "        data_dict = split_and_scale(timeSeries, n_steps_input=n_lag, n_steps_forecast=n_outputs)\n",
        "        resultados, tablas_folds = entrenar_mlp_folds(data_dict, n_outputs=n_outputs,\n",
        "                                                     epochs=epochs, batch_size=batch_size,\n",
        "                                                     verbose_fit=verbose_fit)\n",
        "\n",
        "        # df concatenado de m√©tricas (todos los folds)\n",
        "        df_metricas_comb = pd.concat([t.reset_index(drop=True) for t in tablas_folds], keys=range(1, len(tablas_folds)+1),\n",
        "                                      names=['fold','row']).reset_index()\n",
        "        # resumen por horizonte (mean, std)\n",
        "        df_summary_h = resumen_por_lag(tablas_folds)\n",
        "\n",
        "        # resumen global (media de RMSE, MAE, MAPE, MSE y pval promedio)\n",
        "        rmse_prom = df_metricas_comb.groupby('Horizonte')['RMSE'].mean().mean()  # promedio de horizontes\n",
        "        mae_prom  = df_metricas_comb.groupby('Horizonte')['MAE'].mean().mean()\n",
        "        mape_prom = df_metricas_comb.groupby('Horizonte')['MAPE'].mean().mean()\n",
        "        mse_prom  = df_metricas_comb.groupby('Horizonte')['MSE'].mean().mean()\n",
        "        pvals = df_metricas_comb['BDS_pvalue_h1'].dropna()\n",
        "        pval_prom = pvals.mean() if len(pvals)>0 else np.nan\n",
        "\n",
        "        comparativa_resumen.append({\n",
        "            'n_lag': n_lag,\n",
        "            'RMSE_prom': rmse_prom,\n",
        "            'RMSE_std': df_metricas_comb.groupby('Horizonte')['RMSE'].mean().std(),\n",
        "            'MAE_prom': mae_prom,\n",
        "            'MAPE_prom': mape_prom,\n",
        "            'MSE_prom': mse_prom,\n",
        "            'BDS_pvalue_h1_prom': pval_prom\n",
        "        })\n",
        "\n",
        "        todos_lags[n_lag] = {\n",
        "            'resultados': resultados,         # lista de dict por fold (incluye df_metrics por fold)\n",
        "            'tablas_folds': tablas_folds,     # lista de dataframes por fold\n",
        "            'df_metricas_comb': df_metricas_comb,\n",
        "            'df_summary_h': df_summary_h\n",
        "        }\n",
        "\n",
        "    df_comparativa = pd.DataFrame(comparativa_resumen).sort_values('n_lag').reset_index(drop=True)\n",
        "    return todos_lags, df_comparativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "91DpP6ZnMQTD",
      "metadata": {
        "id": "91DpP6ZnMQTD",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Funciones de plotting\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "def escoger_folds_por_rmse(resultados):\n",
        "    \"\"\"\n",
        "    Recibe lista de resultados (cada uno con 'rmse_test_prom').\n",
        "    Devuelve indices best (min rmse), worst (max rmse) y median (por valor).\n",
        "    \"\"\"\n",
        "    rmses = [r['rmse_test_prom'] for r in resultados]\n",
        "    order = np.argsort(rmses)\n",
        "    best_idx = int(order[0])\n",
        "    worst_idx = int(order[-1])\n",
        "    median_pos = int(len(order)//2)\n",
        "    median_idx = int(order[median_pos])\n",
        "    return best_idx, median_idx, worst_idx\n",
        "\n",
        "\n",
        "def plot_series_fold(resultados_fold, fold_idx, n_steps_input, title_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Grafica las series reales y predichas para un fold espec√≠fico.\n",
        "    \"\"\"\n",
        "    y_train_real = resultados_fold['y_train_real']\n",
        "    y_train_pred = resultados_fold['y_train_pred']\n",
        "    y_val_real   = resultados_fold['y_val_real']\n",
        "    y_val_pred   = resultados_fold['y_val_pred']\n",
        "    y_test_real  = resultados_fold['y_test_real']\n",
        "    y_test_pred  = resultados_fold['y_test_pred']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    # Entrenamiento\n",
        "    ax.plot(y_train_real[:, 0], label='Train Real', color='tab:blue', alpha=0.6)\n",
        "    ax.plot(y_train_pred[:, 0], label='Train Predicho', color='tab:cyan', linestyle='--', alpha=0.8)\n",
        "\n",
        "    # Validaci√≥n\n",
        "    ax.plot(range(len(y_train_real), len(y_train_real)+len(y_val_real)),\n",
        "             y_val_real[:, 0], label='Val Real', color='tab:orange', alpha=0.6)\n",
        "    ax.plot(range(len(y_train_real), len(y_train_real)+len(y_val_pred)),\n",
        "             y_val_pred[:, 0], label='Val Predicho', color='tab:red', linestyle='--', alpha=0.8)\n",
        "\n",
        "    # Test\n",
        "    ax.plot(range(len(y_train_real)+len(y_val_real),\n",
        "                  len(y_train_real)+len(y_val_real)+len(y_test_real)),\n",
        "             y_test_real[:, 0], label='Test Real', color='tab:green', alpha=0.6)\n",
        "    ax.plot(range(len(y_train_real)+len(y_val_real),\n",
        "                  len(y_train_real)+len(y_val_real)+len(y_test_pred)),\n",
        "             y_test_pred[:, 0], label='Test Predicho', color='tab:purple', linestyle='--', alpha=0.8)\n",
        "\n",
        "    ax.set_title(f\"{title_prefix} | Fold {fold_idx+1} | Ventana = {n_steps_input}\")\n",
        "    ax.set_xlabel(\"Tiempo\")\n",
        "    ax.set_ylabel(\"Valor (Volatilidad o Precio)\")\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_rmse_bars(resultados, n_steps_input):\n",
        "    \"\"\"\n",
        "    Grafica barras con el RMSE promedio por fold.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    rmses = [r['rmse_test_prom'] for r in resultados]\n",
        "    folds = np.arange(1, len(rmses)+1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.bar(folds, rmses, color='skyblue', edgecolor='k')\n",
        "    ax.set_title(f\"RMSE por Fold | Ventana = {n_steps_input}\")\n",
        "    ax.set_xlabel(\"Fold\")\n",
        "    ax.set_ylabel(\"RMSE promedio (test)\")\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for i, v in enumerate(rmses):\n",
        "        ax.text(folds[i], v, f\"{v:.3f}\", ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_rmse_promedio_por_horizonte(df_summary_h, n_steps_input):\n",
        "    \"\"\"\n",
        "    Muestra el RMSE promedio (y std si existe) por horizonte.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "    ax.plot(df_summary_h.index, df_summary_h['RMSE_mean'], marker='o', label='RMSE promedio')\n",
        "\n",
        "    if 'RMSE_std' in df_summary_h.columns:\n",
        "        ax.fill_between(df_summary_h.index,\n",
        "                        df_summary_h['RMSE_mean'] - df_summary_h['RMSE_std'],\n",
        "                        df_summary_h['RMSE_mean'] + df_summary_h['RMSE_std'],\n",
        "                        color='blue', alpha=0.2, label='Desviaci√≥n est√°ndar')\n",
        "\n",
        "    ax.set_title(f\"RMSE promedio por horizonte | Ventana = {n_steps_input}\")\n",
        "    ax.set_xlabel(\"Horizonte de predicci√≥n (h)\")\n",
        "    ax.set_ylabel(\"RMSE\")\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "64q0ICIyMQQY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64q0ICIyMQQY",
        "outputId": "ab97ff98-048f-44cd-b560-a029ef1ea823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Procesando n_lag = 7 ===\n",
            "Fold 1: train (325, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 2: train (324, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 3: train (323, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 4: train (322, 98) -> val (108, 98) -> test (108, 98)\n",
            "Fold 5: train (324, 98) -> val (108, 98) -> test (108, 98)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Fold 1 | RMSE prom: 0.0693 | pval(h1): 0.8915469129181351\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Fold 2 | RMSE prom: 0.0698 | pval(h1): 0.005072758465731627\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Fold 3 | RMSE prom: 0.0605 | pval(h1): 0.142210402547321\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Fold 4 | RMSE prom: 0.0574 | pval(h1): 0.8528499679260553\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Fold 5 | RMSE prom: 0.0545 | pval(h1): 0.2735043577885697\n",
            "\n",
            "‚úÖ Mejor fold: 5 con RMSE promedio 0.0545\n",
            "\n",
            "=== Procesando n_lag = 14 ===\n",
            "Fold 1: train (172, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 2: train (171, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 3: train (170, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 4: train (169, 196) -> val (56, 196) -> test (56, 196)\n",
            "Fold 5: train (168, 196) -> val (57, 196) -> test (56, 196)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Fold 1 | RMSE prom: 0.0603 | pval(h1): 0.663501652382756\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Fold 2 | RMSE prom: 0.0703 | pval(h1): 0.7309500588191589\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Fold 3 | RMSE prom: 0.0624 | pval(h1): 0.7136732959235365\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Fold 4 | RMSE prom: 0.0570 | pval(h1): 0.2670260805064777\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Fold 5 | RMSE prom: 0.0634 | pval(h1): 0.15482532229771956\n",
            "\n",
            "‚úÖ Mejor fold: 4 con RMSE promedio 0.0570\n",
            "\n",
            "=== Procesando n_lag = 21 ===\n",
            "Fold 1: train (115, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 2: train (114, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 3: train (113, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 4: train (112, 294) -> val (38, 294) -> test (38, 294)\n",
            "Fold 5: train (114, 294) -> val (38, 294) -> test (38, 294)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Fold 1 | RMSE prom: 0.1257 | pval(h1): 0.7676074377976149\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Fold 2 | RMSE prom: 0.1186 | pval(h1): 0.6690095592742681\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Fold 3 | RMSE prom: 0.1097 | pval(h1): 0.6786990695155504\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Fold 4 | RMSE prom: 0.0908 | pval(h1): 0.7199433490984672\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Fold 5 | RMSE prom: 0.0902 | pval(h1): 0.946842633961309\n",
            "\n",
            "‚úÖ Mejor fold: 5 con RMSE promedio 0.0902\n",
            "\n",
            "=== Procesando n_lag = 28 ===\n",
            "Fold 1: train (88, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 2: train (87, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 3: train (86, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 4: train (85, 392) -> val (29, 392) -> test (28, 392)\n",
            "Fold 5: train (84, 392) -> val (29, 392) -> test (29, 392)\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Fold 1 | RMSE prom: 0.0850 | pval(h1): 0.9154979439464628\n",
            "\n",
            "===== Fold 2/5 =====\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 48ms/stepWARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000241583B54E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Fold 2 | RMSE prom: 0.0839 | pval(h1): 0.1444715644133209\n",
            "\n",
            "===== Fold 3/5 =====\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000241585E9B20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 3 | RMSE prom: 0.1072 | pval(h1): 0.3111625130512544\n",
            "\n",
            "===== Fold 4/5 =====\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 4 | RMSE prom: 0.0885 | pval(h1): 0.5707525326130864\n",
            "\n",
            "===== Fold 5/5 =====\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Fold 5 | RMSE prom: 0.0929 | pval(h1): 0.9773271786913998\n",
            "\n",
            "‚úÖ Mejor fold: 2 con RMSE promedio 0.0839\n"
          ]
        }
      ],
      "source": [
        "# 1) Ejecutar evaluaci√≥n completa\n",
        "todos_lags, df_comparativa = evaluar_y_reportar(timeSeries, lags_list=[7,14,21,28],\n",
        "                                                n_outputs=7, epochs=80, batch_size=32,\n",
        "                                                verbose_fit=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c22d131",
      "metadata": {},
      "source": [
        "En la etapa de modelado de volatilidad, se evalu√≥ el desempe√±o del modelo bajo diferentes configuraciones de retardos temporales (7, 14, 21 y 28 d√≠as). Los resultados muestran un comportamiento estable para horizontes cortos, con valores promedio de RMSE entre 0.06 y 0.07 para los modelos con 7 y 14 lags, indicando una adecuada capacidad del modelo para capturar la variabilidad de corto plazo en la serie.\n",
        "\n",
        "A medida que se incrementa la ventana de rezagos (21 y 28 d√≠as), se observa un aumento gradual del error (RMSE entre 0.09 y 0.11), lo que sugiere una p√©rdida de precisi√≥n debido a la menor cantidad de datos efectivos para el entrenamiento y la posible diluci√≥n de patrones recientes. Los valores del p-valor del test BDS en la mayor√≠a de los pliegues superan el umbral de significancia (p > 0.05), lo que sugiere que los residuales no presentan dependencias no lineales relevantes, respaldando la validez del modelo en t√©rminos de independencia temporal.\n",
        "\n",
        "En general, el modelo logra una representaci√≥n coherente del comportamiento din√°mico de la volatilidad, especialmente en horizontes cortos, donde la memoria reciente del mercado parece ser m√°s informativa para la predicci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffba99e9",
      "metadata": {},
      "source": [
        "### *Tabla de Resumen Comparativo por Lags*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f4bQ0sDpNzyo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "f4bQ0sDpNzyo",
        "outputId": "d6db3b77-2895-4d9d-9f71-2c93cf01b049"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_lag</th>\n",
              "      <th>RMSE_prom</th>\n",
              "      <th>RMSE_std</th>\n",
              "      <th>MAE_prom</th>\n",
              "      <th>MAPE_prom</th>\n",
              "      <th>MSE_prom</th>\n",
              "      <th>BDS_pvalue_h1_prom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0.062286</td>\n",
              "      <td>0.009220</td>\n",
              "      <td>0.038070</td>\n",
              "      <td>6.741061</td>\n",
              "      <td>0.004175</td>\n",
              "      <td>0.433037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.062680</td>\n",
              "      <td>0.015837</td>\n",
              "      <td>0.044752</td>\n",
              "      <td>7.859136</td>\n",
              "      <td>0.004328</td>\n",
              "      <td>0.505995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0.106995</td>\n",
              "      <td>0.033413</td>\n",
              "      <td>0.068251</td>\n",
              "      <td>11.930163</td>\n",
              "      <td>0.013246</td>\n",
              "      <td>0.756420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.015232</td>\n",
              "      <td>0.066055</td>\n",
              "      <td>11.799854</td>\n",
              "      <td>0.008978</td>\n",
              "      <td>0.583842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_lag  RMSE_prom  RMSE_std  MAE_prom  MAPE_prom  MSE_prom  \\\n",
              "0      7   0.062286  0.009220  0.038070   6.741061  0.004175   \n",
              "1     14   0.062680  0.015837  0.044752   7.859136  0.004328   \n",
              "2     21   0.106995  0.033413  0.068251  11.930163  0.013246   \n",
              "3     28   0.091503  0.015232  0.066055  11.799854  0.008978   \n",
              "\n",
              "   BDS_pvalue_h1_prom  \n",
              "0            0.433037  \n",
              "1            0.505995  \n",
              "2            0.756420  \n",
              "3            0.583842  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2) Ver tabla resumen comparativa de los 4 lags:\n",
        "df_comparativa.to_csv(r'C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\tablas\\resumen_comparativo.csv', index=False)\n",
        "df_comparativa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbaa461",
      "metadata": {},
      "source": [
        "Los resultados del modelo para la predicci√≥n de volatilidad del Bitcoin muestran un desempe√±o estable y coherente a trav√©s de las distintas configuraciones de retardos. Los menores errores promedio se observan con lags de 7 y 14 d√≠as, con valores de RMSE ‚âà 0.065 y MAE ‚âà 0.04‚Äì0.045, lo que evidencia una buena capacidad del modelo para capturar la din√°mica de corto plazo.\n",
        "\n",
        "En cambio, al incrementar la memoria temporal (lags de 21 y 28 d√≠as), los errores aumentan ligeramente (RMSE entre 0.09 y 0.11), lo que sugiere que incluir retardos m√°s largos introduce ruido o patrones menos relevantes para la predicci√≥n inmediata.\n",
        "\n",
        "El MAPE, que se mantiene entre 7% y 12%, refuerza la estabilidad general del modelo en t√©rminos relativos.\n",
        "Finalmente, los valores del p-valor del test BDS (entre 0.52 y 0.71) superan el umbral de significancia (0.05), indicando que los residuales no presentan dependencias no lineales, por lo que el modelo logra capturar adecuadamente la estructura temporal de la volatilidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "q9gQHPmZNzxR",
      "metadata": {
        "id": "q9gQHPmZNzxR",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def resultados_lag_vol(n_lag):\n",
        "    # 3) Para un lag espec√≠fico:\n",
        "    info = todos_lags[n_lag]\n",
        "    resultados = info['resultados']   # lista por fold\n",
        "    tablas_folds = info['tablas_folds']\n",
        "    df_metricas_comb = info['df_metricas_comb']\n",
        "    df_summary_h = info['df_summary_h']\n",
        "\n",
        "    # Crear carpetas si no existen\n",
        "    base_dir = fr'C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad'\n",
        "    tablas_dir = os.path.join(base_dir, 'tablas', f'lag_{n_lag}')\n",
        "    figs_dir = os.path.join(base_dir, 'figs', f'lag_{n_lag}')\n",
        "    os.makedirs(tablas_dir, exist_ok=True)\n",
        "    os.makedirs(figs_dir, exist_ok=True)\n",
        "\n",
        "    # 4) Guardar tablas por fold (test)\n",
        "    for i, df in enumerate(tablas_folds):\n",
        "        print(f\"\\n--- Fold {i+1} ---\")\n",
        "        df_path = os.path.join(tablas_dir, f'fold_{i+1}_lag_{n_lag}.csv')\n",
        "        df.to_csv(df_path, index=False)\n",
        "        print(df)\n",
        "\n",
        "    # 5) Seleccionar best/median/worst y plotear\n",
        "    best, med, worst = escoger_folds_por_rmse(resultados)\n",
        "\n",
        "    # Mejor\n",
        "    fig = plot_series_fold(resultados[best], best, n_steps_input=n_lag, title_prefix=\"Mejor (RMSE)\")\n",
        "    fig.savefig(os.path.join(figs_dir, f'mejor_rmse_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Mediano\n",
        "    fig = plot_series_fold(resultados[med], med, n_steps_input=n_lag, title_prefix=\"Mediano (RMSE)\")\n",
        "    fig.savefig(os.path.join(figs_dir, f'mediano_rmse_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Peor\n",
        "    fig = plot_series_fold(resultados[worst], worst, n_steps_input=n_lag, title_prefix=\"Peor (RMSE)\")\n",
        "    fig.savefig(os.path.join(figs_dir, f'peor_rmse_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # 6) Gr√°ficas adicionales\n",
        "    fig = plot_rmse_bars(resultados, n_steps_input=n_lag)\n",
        "    fig.savefig(os.path.join(figs_dir, f'rmse_por_fold_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = plot_rmse_promedio_por_horizonte(df_summary_h, n_steps_input=n_lag)\n",
        "    fig.savefig(os.path.join(figs_dir, f'rmse_promedio_por_horizonte_lag_{n_lag}.png'), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    print(f\"\\n‚úÖ Resultados y gr√°ficas guardados en: {figs_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42ee12f8",
      "metadata": {},
      "source": [
        "### *Tablas de Metricas: Resumen por Horizonte y por Fold*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a4dzre1PNzqn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4dzre1PNzqn",
        "outputId": "985b3203-375f-4116-84b5-7a5f8b91756f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE      MAPE  BDS_pvalue_h1\n",
            "0         1  0.037487  0.010490  0.102420  6.743446       0.891547\n",
            "1         2  0.036673  0.002706  0.052023  6.757439            NaN\n",
            "2         3  0.036455  0.003305  0.057486  6.473721            NaN\n",
            "3         4  0.043625  0.006507  0.080668  6.620333            NaN\n",
            "4         5  0.039824  0.003210  0.056658  7.597544            NaN\n",
            "5         6  0.031414  0.004778  0.069124  4.358839            NaN\n",
            "6         7  0.029271  0.004475  0.066892  3.993403            NaN\n",
            "7  Promedio  0.036393  0.005067  0.069324  6.077818            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE      MAPE  BDS_pvalue_h1\n",
            "0         1  0.041829  0.005825  0.076321  8.499314       0.005073\n",
            "1         2  0.040635  0.003032  0.055062  6.992410            NaN\n",
            "2         3  0.045862  0.004675  0.068376  8.276422            NaN\n",
            "3         4  0.052068  0.006957  0.083410  8.312861            NaN\n",
            "4         5  0.043751  0.003257  0.057068  8.372988            NaN\n",
            "5         6  0.036428  0.003801  0.061654  6.091387            NaN\n",
            "6         7  0.036950  0.007480  0.086489  5.386906            NaN\n",
            "7  Promedio  0.042503  0.005004  0.069768  7.418898            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE      MAPE  BDS_pvalue_h1\n",
            "0         1  0.026841  0.001374  0.037071  5.149154        0.14221\n",
            "1         2  0.044535  0.003806  0.061695  7.528908            NaN\n",
            "2         3  0.040332  0.006373  0.079828  6.179189            NaN\n",
            "3         4  0.051228  0.009356  0.096729  9.539231            NaN\n",
            "4         5  0.041930  0.003330  0.057707  7.782203            NaN\n",
            "5         6  0.029497  0.001934  0.043978  5.708057            NaN\n",
            "6         7  0.025664  0.002137  0.046226  4.708031            NaN\n",
            "7  Promedio  0.037147  0.004044  0.060462  6.656396            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.023821  0.001009  0.031766   4.535149        0.85285\n",
            "1         2  0.042511  0.003084  0.055532   7.407713            NaN\n",
            "2         3  0.045702  0.006098  0.078091   7.235340            NaN\n",
            "3         4  0.048574  0.005597  0.074812  10.170363            NaN\n",
            "4         5  0.041077  0.002928  0.054115   7.435645            NaN\n",
            "5         6  0.029011  0.002415  0.049140   5.261197            NaN\n",
            "6         7  0.033676  0.003373  0.058081   6.009937            NaN\n",
            "7  Promedio  0.037767  0.003501  0.057362   6.865049            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.035406  0.002077  0.045569   6.515542       0.273504\n",
            "1         2  0.036646  0.004245  0.065156   5.891489            NaN\n",
            "2         3  0.055793  0.008139  0.090218  11.313055            NaN\n",
            "3         4  0.039432  0.002909  0.053931   7.146203            NaN\n",
            "4         5  0.034744  0.002473  0.049727   6.417249            NaN\n",
            "5         6  0.027597  0.001378  0.037126   4.822254            NaN\n",
            "6         7  0.026165  0.001588  0.039850   4.704212            NaN\n",
            "7  Promedio  0.036540  0.003258  0.054511   6.687143            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_7\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "016CwUJUNzoD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "016CwUJUNzoD",
        "outputId": "78cc3c19-2dbf-4162-e2e6-4ba414cc0980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.034595  0.002171  0.046596   6.316844       0.663502\n",
            "1         2  0.028874  0.002229  0.047214   4.741901            NaN\n",
            "2         3  0.040861  0.004049  0.063635   6.150395            NaN\n",
            "3         4  0.053933  0.007572  0.087016   8.189806            NaN\n",
            "4         5  0.059110  0.007552  0.086904  10.396623            NaN\n",
            "5         6  0.030067  0.001559  0.039479   5.664456            NaN\n",
            "6         7  0.033609  0.002626  0.051243   6.360378            NaN\n",
            "7  Promedio  0.040150  0.003965  0.060298   6.831486            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.040478  0.002613  0.051121   7.089398        0.73095\n",
            "1         2  0.041996  0.003173  0.056325   6.879242            NaN\n",
            "2         3  0.048059  0.003820  0.061810   8.361545            NaN\n",
            "3         4  0.065098  0.009452  0.097220   9.891707            NaN\n",
            "4         5  0.071298  0.011380  0.106679  11.796785            NaN\n",
            "5         6  0.039745  0.002583  0.050827   6.897184            NaN\n",
            "6         7  0.052681  0.004623  0.067989  10.040535            NaN\n",
            "7  Promedio  0.051336  0.005378  0.070282   8.708057            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.046333  0.004695  0.068519   7.639098       0.713673\n",
            "1         2  0.034543  0.002091  0.045730   6.220421            NaN\n",
            "2         3  0.041528  0.002524  0.050235   7.486923            NaN\n",
            "3         4  0.042844  0.003102  0.055698   7.637392            NaN\n",
            "4         5  0.056725  0.008868  0.094168  11.283551            NaN\n",
            "5         6  0.043376  0.003879  0.062284   7.241633            NaN\n",
            "6         7  0.042998  0.003634  0.060285   7.544025            NaN\n",
            "7  Promedio  0.044050  0.004113  0.062417   7.864721            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.034733  0.001975  0.044443   6.356004       0.267026\n",
            "1         2  0.036357  0.002143  0.046293   6.659096            NaN\n",
            "2         3  0.046828  0.004024  0.063435   7.789387            NaN\n",
            "3         4  0.052868  0.004902  0.070013   8.073615            NaN\n",
            "4         5  0.056773  0.005868  0.076600  11.047421            NaN\n",
            "5         6  0.038757  0.002993  0.054705   6.663851            NaN\n",
            "6         7  0.036362  0.001916  0.043766   6.922320            NaN\n",
            "7  Promedio  0.043240  0.003403  0.057036   7.644528            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.025370  0.001058  0.032522   4.897615       0.154825\n",
            "1         2  0.039321  0.002342  0.048392   6.655689            NaN\n",
            "2         3  0.064609  0.009385  0.096877  11.113908            NaN\n",
            "3         4  0.064130  0.011365  0.106609  12.459347            NaN\n",
            "4         5  0.057325  0.005858  0.076540  10.856407            NaN\n",
            "5         6  0.029844  0.001400  0.037421   5.588160            NaN\n",
            "6         7  0.034294  0.002042  0.045189   6.157100            NaN\n",
            "7  Promedio  0.044985  0.004779  0.063364   8.246889            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_14\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "gCs1V7d0Nzkx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gCs1V7d0Nzkx",
        "outputId": "0a494676-7714-452c-c937-74f11231b829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.086956  0.029092  0.170563  13.287351       0.767607\n",
            "1         2  0.073124  0.009465  0.097287  13.410948            NaN\n",
            "2         3  0.052059  0.004170  0.064573   9.095380            NaN\n",
            "3         4  0.069181  0.007379  0.085901  12.541135            NaN\n",
            "4         5  0.056203  0.006236  0.078971  11.180129            NaN\n",
            "5         6  0.089295  0.043616  0.208844  11.705412            NaN\n",
            "6         7  0.087969  0.030292  0.174047  13.779760            NaN\n",
            "7  Promedio  0.073541  0.018607  0.125741  12.142874            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.091547  0.032640  0.180665  13.819671        0.66901\n",
            "1         2  0.069776  0.011543  0.107436  13.614970            NaN\n",
            "2         3  0.079442  0.009391  0.096909  15.100938            NaN\n",
            "3         4  0.065571  0.006948  0.083357  13.854645            NaN\n",
            "4         5  0.038326  0.002389  0.048875   7.266991            NaN\n",
            "5         6  0.092758  0.026894  0.163994  15.439995            NaN\n",
            "6         7  0.094850  0.022138  0.148790  16.320405            NaN\n",
            "7  Promedio  0.076039  0.015992  0.118575  13.631088            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.070384  0.014967  0.122341  12.613230       0.678699\n",
            "1         2  0.070781  0.008926  0.094480  14.042629            NaN\n",
            "2         3  0.073230  0.008614  0.092811  13.127035            NaN\n",
            "3         4  0.066208  0.007200  0.084855  13.100927            NaN\n",
            "4         5  0.041366  0.002937  0.054196   8.169428            NaN\n",
            "5         6  0.089603  0.033032  0.181746  12.868252            NaN\n",
            "6         7  0.073305  0.018893  0.137451  10.717844            NaN\n",
            "7  Promedio  0.069268  0.013510  0.109697  12.091335            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.065108  0.010336  0.101667  10.272405       0.719943\n",
            "1         2  0.057402  0.006744  0.082122  10.718000            NaN\n",
            "2         3  0.058549  0.006618  0.081352  10.870209            NaN\n",
            "3         4  0.065320  0.007015  0.083755  13.015234            NaN\n",
            "4         5  0.035240  0.002247  0.047403   6.405708            NaN\n",
            "5         6  0.052824  0.006854  0.082789   9.413746            NaN\n",
            "6         7  0.076265  0.024481  0.156464  13.144770            NaN\n",
            "7  Promedio  0.058673  0.009185  0.090793  10.548582            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.057846  0.006568  0.081041   9.843403       0.946843\n",
            "1         2  0.046214  0.003893  0.062393   7.688255            NaN\n",
            "2         3  0.067125  0.013974  0.118211   9.744263            NaN\n",
            "3         4  0.044885  0.003618  0.060153   7.987844            NaN\n",
            "4         5  0.056800  0.004647  0.068166  11.999016            NaN\n",
            "5         6  0.075998  0.010212  0.101054  12.839224            NaN\n",
            "6         7  0.097265  0.019649  0.140176  18.556545            NaN\n",
            "7  Promedio  0.063733  0.008937  0.090170  11.236936            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_21\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "vK58Cru9PGqF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vK58Cru9PGqF",
        "outputId": "bfdb99b0-7845-40b4-8963-1b4c02d6546c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.054831  0.004753  0.068945   9.442787       0.915498\n",
            "1         2  0.068354  0.008773  0.093664  10.821783            NaN\n",
            "2         3  0.061655  0.007321  0.085561  13.322803            NaN\n",
            "3         4  0.051690  0.005566  0.074604   8.857666            NaN\n",
            "4         5  0.076874  0.010780  0.103828  15.025700            NaN\n",
            "5         6  0.059571  0.006328  0.079550  11.420390            NaN\n",
            "6         7  0.071440  0.007922  0.089008  12.256295            NaN\n",
            "7  Promedio  0.063488  0.007349  0.085023  11.592489            NaN\n",
            "\n",
            "--- Fold 2 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.055755  0.007502  0.086614   9.510814       0.144472\n",
            "1         2  0.051335  0.004167  0.064553   8.385306            NaN\n",
            "2         3  0.058653  0.005677  0.075347  11.802276            NaN\n",
            "3         4  0.048319  0.004614  0.067930   9.176949            NaN\n",
            "4         5  0.068986  0.009265  0.096257  12.332538            NaN\n",
            "5         6  0.082470  0.010966  0.104721  14.554658            NaN\n",
            "6         7  0.069778  0.008449  0.091916  12.794294            NaN\n",
            "7  Promedio  0.062185  0.007234  0.083905  11.222405            NaN\n",
            "\n",
            "--- Fold 3 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.097138  0.015361  0.123941  18.758815       0.311163\n",
            "1         2  0.101875  0.017210  0.131186  16.709176            NaN\n",
            "2         3  0.066031  0.007140  0.084501  11.846017            NaN\n",
            "3         4  0.056997  0.005128  0.071613  10.316672            NaN\n",
            "4         5  0.082156  0.011758  0.108434  17.226624            NaN\n",
            "5         6  0.086307  0.010462  0.102284  16.333576            NaN\n",
            "6         7  0.098734  0.016542  0.128617  17.553097            NaN\n",
            "7  Promedio  0.084177  0.011943  0.107225  15.534854            NaN\n",
            "\n",
            "--- Fold 4 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.066280  0.006815  0.082551  11.702661       0.570753\n",
            "1         2  0.047352  0.003784  0.061516   8.088757            NaN\n",
            "2         3  0.044961  0.002907  0.053918   9.465315            NaN\n",
            "3         4  0.051723  0.005259  0.072519   9.826777            NaN\n",
            "4         5  0.087973  0.027356  0.165397  15.188935            NaN\n",
            "5         6  0.054002  0.005121  0.071559  10.140723            NaN\n",
            "6         7  0.080287  0.012488  0.111749  13.457152            NaN\n",
            "7  Promedio  0.061797  0.009104  0.088459  11.124331            NaN\n",
            "\n",
            "--- Fold 5 ---\n",
            "  Horizonte       MAE       MSE      RMSE       MAPE  BDS_pvalue_h1\n",
            "0         1  0.064519  0.012103  0.110014  10.277165       0.977327\n",
            "1         2  0.052154  0.004056  0.063690  10.134229            NaN\n",
            "2         3  0.046605  0.007131  0.084444   7.014133            NaN\n",
            "3         4  0.051898  0.005108  0.071469   7.967996            NaN\n",
            "4         5  0.070997  0.008106  0.090031  11.861718            NaN\n",
            "5         6  0.053077  0.007421  0.086143   8.490913            NaN\n",
            "6         7  0.071138  0.020890  0.144533  10.930182            NaN\n",
            "7  Promedio  0.058627  0.009259  0.092904   9.525191            NaN\n",
            "\n",
            "‚úÖ Resultados y gr√°ficas guardados en: C:\\DeepLearning\\DL_Proyecto_2\\data\\volatilidad\\figs\\lag_28\n"
          ]
        }
      ],
      "source": [
        "resultados_lag_vol(28)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
